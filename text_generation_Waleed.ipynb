{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "378d1e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996980428695679}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Allocate a pipeline for sentiment-analysis\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('We are very happy to introduce pipeline to the transformers repository.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f0c6e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.30970150232315063,\n",
       " 'start': 34,\n",
       " 'end': 58,\n",
       " 'answer': 'huggingface/transformers'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline('question-answering')\n",
    "question_answerer({\n",
    "    'question': 'What is the name of the repository ?',\n",
    "     'context': 'Pipeline has been included in the huggingface/transformers repository'\n",
    " })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42ae8d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, I use\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I\"},\n",
       " {'generated_text': \"Hello, I'm a language model, so you\"},\n",
       " {'generated_text': \"Hello, I'm a language model, a system\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I do\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I'm\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, so I\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I mean\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, i.\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, like everybody\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and that\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and you\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I understand\"},\n",
       " {'generated_text': \"Hello, I'm a language model, we need\"},\n",
       " {'generated_text': \"Hello, I'm a language model, my name\"},\n",
       " {'generated_text': \"Hello, I'm a language model, it's\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, for those\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, but a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I want\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I'm\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I think\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a\"},\n",
       " {'generated_text': \"Hello, I'm a language model, because I\"},\n",
       " {'generated_text': \"Hello, I'm a language model, an interpreter\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I\"},\n",
       " {'generated_text': \"Hello, I'm a language model, what languages\"}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=10, num_return_sequences=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4109c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'As far as I am concerned, I will be the first to admit that I am not a fan of the idea of a \"free market.\" I think that the idea of a free market is a bit of a stretch. I think that the idea'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "print(text_generator(\"As far as I am concerned, I will\", max_length=50, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54d10609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"The Black man worked as a manager and he told me after being hired that after he got out there he knew how much it would take for him to earn $20,000. He says, 'I need all of these jobs and that's all\"},\n",
       " {'generated_text': 'The Black man worked as a \"master operator\" at a large food processing plant in Texas, but now, on a contract extension from a local law-enforcement union, he says he could be fired for stealing food to pay the rent. Because his'},\n",
       " {'generated_text': 'The Black man worked as a manger and would have worked as a painter. He was a young man of only 19. He was also rich and had the last name of a rich man. He became one of the richest people ever. He spent'},\n",
       " {'generated_text': \"The Black man worked as a barber, a parlor teacher and a security guard, and then did his usual job at the grocery store. His job wasn't just to help the black people in the area but to help sell food to people who\"},\n",
       " {'generated_text': \"The Black man worked as a carpenter. He saw a man come into his shop, and he heard some noises, and asked, 'Come, tell my brother a big lie, if you please?' He laughed at him like a jack-pole\"}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"The White man worked as a\", max_length=50, num_return_sequences=5)\n",
    "#set_seed(42)\n",
    "generator(\"The Black man worked as a\", max_length=50, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f240520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transforms library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8038820028305054, 0.1386091262102127, 0.0575089305639267]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# The zero-shot-classification pipline lets you select the label classification\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier ( \"This is a course about the Transforms library\",\n",
    "               candidate_labels=[\"education\" , \"politics\" ,\"business\"],\n",
    "               \n",
    ")\n",
    "# it more about education than the other labels ,with confidence of 80% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bae77a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course , we will teach you how to configure your PHP to execute a callbacks. It will enable you to write code that will respond to calls to your scripts.\\n\\nIf you have completed the course from now onward here is an explanation'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text generation pipline will auto-complete a given prompt\n",
    "# the output is generated with a  a bit of randomnes\n",
    "# it changes each time you call the generator object on a given prompt\n",
    "\n",
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation')\n",
    "generator(\"In this course , we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50f574f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course , we will teach you how to integrate our courses into our programs which are very unique and exciting for you.\\nIn our upcoming courses'},\n",
       " {'generated_text': 'In this course , we will teach you how to read and parse text in Haskell.\\n\\n\\n\\nNow, I want to explain my new language'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used distilgpt2 model\n",
    "# it is a lighter version of gpt2\n",
    "# when applying the pipeline to a given prompt\n",
    "# we can specify several arguments  , such as max_length of the generate text\n",
    "# num_return_sequences : number of sequence we want to return (since there is some randomness in the generation )\n",
    "\n",
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation' , model= 'distilgpt2')\n",
    "generator(\"In this course , we will teach you how to\" ,\n",
    "         max_length=30,\n",
    "         num_return_sequences=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20f210d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'In this course, we will teach you all about mathematical models. ',\n",
       "  'score': 0.1854812353849411,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical'},\n",
       " {'sequence': 'In this course, we will teach you all about computational models. ',\n",
       "  'score': 0.030585043132305145,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fill mask pipline will predict missing words in sentence\n",
    "# which is to guess the value of the masked word . in this case , we ask the two most likely values for the missing word\n",
    "# \n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask')\n",
    "unmasker (\"In this course , we will teach you all about<mask> models. \" , top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "743616f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99919486,\n",
       "  'word': 'Smith',\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9906017,\n",
       "  'word': 'EC Utbiliding',\n",
       "  'start': 32,\n",
       "  'end': 46},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.97117496,\n",
       "  'word': 'Malmö',\n",
       "  'start': 50,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The NER pipeline identifies enttities such as organization or location in the sentence instead of the sentence as whole\n",
    "# The model correctly finds the peson (Smith)\n",
    "# And the orgnization (Ec EC  Utbiliding )\n",
    "# And the Locatin (Malmö)\n",
    "# grouped_entities = True argument used is to make the pipline group together\n",
    "\n",
    "from transformers import pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities = True)\n",
    "ner(\"My name is Smith  and I work at EC  Utbiliding in Malmö\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37533717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
